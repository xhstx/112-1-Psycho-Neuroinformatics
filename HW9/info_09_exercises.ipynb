{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psychoinformatics - Week 9 (Exercises)\n",
    "by 徐舒庭 (b11705018@ntu.edu.tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn import model_selection\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 檢查 machine learning pipeline (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 請打亂原本的Y觀察正確率是否和chance level (0.33)有差異? 若有, why? (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y= [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Y2= [1 1 1 2 2 1 0 1 2 0 2 0 2 0 1 0 1 0 2 0 0 2 2 1 1 1 2 1 2 0 0 2 1 0 0 2 1\n",
      " 1 2 0 2 1 1 1 1 1 0 2 2 0 2 1 2 2 1 1 1 0 0 0 1 1 2 1 2 0 1 0 0 0 0 0 1 2\n",
      " 2 0 0 0 1 2 1 1 2 0 0 2 0 2 0 2 0 0 1 2 2 2 2 1 2 2 1 1 0 0 1 0 1 1 0 2 0\n",
      " 0 2 0 1 2 1 2 2 2 0 0 1 0 2 2 2 2 0 1 1 1 0 0 0 2 0 1 1 2 1 2 1 2 1 0 1 0\n",
      " 2 2]\n",
      "原正確率: 0.3\n",
      "新正確率: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 本題在研究打亂X和打亂Y有差別嗎?\n",
    "iris = datasets.load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "Y2=np.random.permutation(Y)\n",
    "print(\"Y=\", Y)\n",
    "print(\"Y2=\", Y2)\n",
    "clf=neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(X,Y2)\n",
    "orig_accuracy=np.mean(clf.predict(X)==Y)\n",
    "new_accuracy=np.mean(clf.predict(X)==Y2)\n",
    "ac=np.mean(clf.predict(X)==Y)\n",
    "print(\"原正確率:\", orig_accuracy)\n",
    "print(\"新正確率:\", new_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有差異。在原本的Y中，類別標籤的分佈是有順序的，而KNeighborsClassifier會選擇K個最近鄰中出現最多次的類别作为待分類樣本的類别，此時，因有序排列，同一種類別會聚集。然而，在打亂Y之後，類別標籤的分佈較為均勻。這可能有助於分類器更好地泛化到未見過的數據，提高分類的正確率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 請用母數或無母數統計檢定以下accuracies中的結果是否和chance level (0.5)有差異? 若有, why? (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "Y=np.remainder(range(200),2) \n",
    "print(Y) #Y的0和1個數一樣多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跑一百次測試:\n",
    "clf=svm.SVC()\n",
    "accuracies=[]\n",
    "for i in range(100): \n",
    " X=np.random.rand(200,2) # X取亂數\n",
    " kf=model_selection.KFold(len(Y),shuffle=True) # Leave-one-out cross-validation\n",
    " sc=model_selection.cross_val_score(clf,X,Y,cv=kf)\n",
    " accuracies.append(sc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: -1.4713413130333677\n",
      "p value: 0.14437043182525255\n",
      "accuracies與0.5没有顯著差異\n"
     ]
    }
   ],
   "source": [
    "# Please do your statistical tests here:\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "t_statistic, p_value = ttest_1samp(accuracies, 0.5)\n",
    "\n",
    "print(\"t statistic:\", t_statistic)\n",
    "print(\"p value:\", p_value)\n",
    "\n",
    "# 根據p_value判斷是否有差異\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"accuracies與0.5有顯著差異\")\n",
    "else:\n",
    "    print(\"accuracies與0.5没有顯著差異\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有差異\n",
    "\n",
    "t statistic為負數，代表樣本均值小於期望值，正確率在100次實驗中小於0.5。\n",
    "\n",
    "差異原因可能有以下三個：\n",
    "\n",
    "1.随機數據：np.random.rand()會生成一個均匀分布的随機数据，可能不容易被SVM有效地分離，因此無法很好地分類这些數據。\n",
    "\n",
    "2.樣本量和特徵：dataset包含200個數據，每個數據有2個特徵。由於數據和特徵數量較少，對於SVM，通常需要大量的數據和更多的特徵以獲得更好的模型。\n",
    "\n",
    "3.數據分佈：由于數據是随機生成，可能導致類别之間的邊界不明顯，或两個類别的分布重叠多，使分類困難。因為SVM是一種用于處理線性可分或近似線性可分數據的演算法，當數據不滿足，性能可能會下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please submit your notebook in PDF to NTU Cool by next Friday (11/10)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
